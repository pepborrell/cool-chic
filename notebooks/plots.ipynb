{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180f935d",
   "metadata": {},
   "source": [
    "# How to use this for just plotting\n",
    "In case you haven't worked with the repo but want to get these plots, there are some preliminary steps you'll need to follow.\n",
    "1. For now, clone the whole repo (`git clone https://github.com/pepborrell/cool-chic.git`). It takes a while and it's a little heavy but it will make things so much easier.\n",
    "2. Create the environment to run all code in the repo with `uv run python`. If you don't have uv, install it with `curl -LsSf https://astral.sh/uv/install.sh | sh` (or `pip install uv`). Use that environment to run this notebook.\n",
    "2. Theoretically, all necessary data is already in the repo.\n",
    "3. Get the images you need: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b90ad",
   "metadata": {},
   "source": [
    "# Plot 1: RD plots for avgs in a dataset and some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9721d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from coolchic.eval.bd_rate import bd_rates_summary_anchor_name\n",
    "from coolchic.eval.hypernet import (\n",
    "    get_hypernet_flops,\n",
    "    plot_hypernet_rd,\n",
    "    plot_hypernet_rd_avg,\n",
    ")\n",
    "from coolchic.eval.results import SummaryEncodingMetrics, parse_hypernet_metrics\n",
    "from coolchic.hypernet.hypernet import DeltaWholeNet, NOWholeNet\n",
    "from coolchic.utils.paths import DATA_DIR, RESULTS_DIR\n",
    "\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_path = RESULTS_DIR / \"exps/delta-hn/ups-best-orange/\"\n",
    "compare_no_path = RESULTS_DIR / \"exps/no-cchic/orange-best/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rd_plots_from_dataset(dataset: Literal[\"kodak\", \"clic20-pro-valid\"]) -> None:\n",
    "    import pandas as pd\n",
    "\n",
    "    metrics = parse_hypernet_metrics(sweep_path, dataset=dataset, premature=True)\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                [s.model_dump() for seq_res in metrics.values() for s in seq_res]\n",
    "            ).assign(anchor=\"hypernet (ours)\"),\n",
    "            pd.DataFrame(  # For comparison with no hypernet.\n",
    "                [\n",
    "                    s.model_dump()\n",
    "                    for seq_res in parse_hypernet_metrics(\n",
    "                        compare_no_path, dataset, premature=True\n",
    "                    ).values()\n",
    "                    for s in seq_res\n",
    "                ]\n",
    "            ).assign(anchor=\"n-o cool-chic\"),\n",
    "        ],\n",
    "    ).sort_values(by=[\"seq_name\", \"lmbda\"])  # So plots come out nice and in order.\n",
    "\n",
    "    plot_hypernet_rd_avg(df, dataset=dataset)\n",
    "\n",
    "    all_images = sorted(list((DATA_DIR / dataset).glob(\"*.png\")), key=lambda x: x.stem)\n",
    "    for img in all_images[:5]:\n",
    "        seq_name = img.stem\n",
    "        plot_hypernet_rd(seq_name, df, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09de600",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_plots_from_dataset(\"kodak\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_plots_from_dataset(\"clic20-pro-valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2d8de",
   "metadata": {},
   "source": [
    "# Plot 2: flops vs BD-rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a524fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# from coolchic.eval.hypernet import get_hypernet_flops\n",
    "# from coolchic.hypernet.hypernet import DeltaWholeNet, NOWholeNet\n",
    "\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "flops = {\n",
    "    \"coolchic\": (\n",
    "        coolchic_fwd := get_hypernet_flops(DeltaWholeNet, get_coolchic_flops=True)\n",
    "    ),\n",
    "    \"coolchic_step\": 3 * coolchic_fwd,\n",
    "    \"N-O Cool-chic\": get_hypernet_flops(NOWholeNet),\n",
    "    \"Hypernet (ours)\": get_hypernet_flops(DeltaWholeNet),\n",
    "}\n",
    "\n",
    "bd_rates = {\n",
    "    \"kodak\": {\n",
    "        \"N-O Cool-chic\": 37.33,\n",
    "        \"Hypernet (ours)\": 33.60,\n",
    "    },\n",
    "    \"clic20-pro-valid\": {\n",
    "        \"N-O Cool-chic\": 36.233904571367106,\n",
    "        \"Hypernet (ours)\": 28.284958907776783,\n",
    "    },\n",
    "}\n",
    "\n",
    "metrics_dfg = pd.DataFrame(\n",
    "    [\n",
    "        (dataset, method, bd_rate, flops[method])\n",
    "        for dataset, bd_rates in bd_rates.items()\n",
    "        for method, bd_rate in bd_rates.items()\n",
    "    ],\n",
    "    columns=[\"dataset\", \"method\", \"bd_rate\", \"flops\"],\n",
    ")\n",
    "metrics_dfg[\"num_coolchic_steps\"] = metrics_dfg[\"flops\"] / flops[\"coolchic_step\"]\n",
    "metrics_dfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b075013",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(\n",
    "    data=metrics_dfg[metrics_dfg[\"dataset\"] == \"clic20-pro-valid\"],\n",
    "    x=\"num_coolchic_steps\",\n",
    "    y=\"bd_rate\",\n",
    "    hue=\"method\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\"BD Rate vs. Equivalent number of Cool-chic Steps, CLIC20 dataset\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56551e52",
   "metadata": {},
   "source": [
    "# Plot 4: show bd rate vs flops as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fae6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flops = {\n",
    "    \"coolchic\": (\n",
    "        coolchic_fwd := get_hypernet_flops(DeltaWholeNet, get_coolchic_flops=True)\n",
    "    ),\n",
    "    \"coolchic_step\": 3 * coolchic_fwd,\n",
    "    \"N-O Cool-chic\": get_hypernet_flops(NOWholeNet),\n",
    "    \"Hypernet (ours)\": get_hypernet_flops(DeltaWholeNet),\n",
    "}\n",
    "\n",
    "bd_rates = {\n",
    "    \"kodak\": {\n",
    "        \"N-O Cool-chic\": 37.33,\n",
    "        \"Hypernet (ours)\": 33.60,\n",
    "    },\n",
    "    \"clic20-pro-valid\": {\n",
    "        \"N-O Cool-chic\": 36.233904571367106,\n",
    "        \"Hypernet (ours)\": 28.284958907776783,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(\n",
    "    [\n",
    "        (dataset, method, bd_rate, flops[method])\n",
    "        for dataset, bd_rates in bd_rates.items()\n",
    "        for method, bd_rate in bd_rates.items()\n",
    "    ],\n",
    "    columns=[\"dataset\", \"method\", \"bd_rate\", \"flops\"],\n",
    ")\n",
    "metrics_df[\"num_coolchic_steps\"] = metrics_df[\"flops\"] / flops[\"coolchic_step\"]\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"clic20-pro-valid\"\n",
    "# dataset = \"kodak\"\n",
    "method = \"from-orange\"\n",
    "CONFIG_NUM_TO_LMBDA = {\"00\": 0.0001, \"01\": 0.0004, \"02\": 0.001, \"03\": 0.004, \"04\": 0.02}\n",
    "\n",
    "finetuning_dir = RESULTS_DIR / \"finetuning\" / dataset\n",
    "finetuning_df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(file).assign(anchor=f\"{file.parent.stem}-finetuning\")\n",
    "        for file in finetuning_dir.glob(\"**/*.csv\")\n",
    "    ]\n",
    ")\n",
    "finetuning_df = finetuning_df.reset_index(drop=True)\n",
    "finetuning_df[\"anchor\"] = finetuning_df[\"anchor\"].apply(\n",
    "    lambda x: \"N-O Cool-chic finetuning\" if \"nocc\" in x else \"Hypernet finetuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0aa6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bd_rate_from_df(df: pd.DataFrame) -> float:\n",
    "    metrics = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        assert \"seq_name\" in row, \"seq_name column is missing in the DataFrame\"\n",
    "        metrics[row[\"seq_name\"]].append(\n",
    "            SummaryEncodingMetrics(\n",
    "                seq_name=row[\"seq_name\"],\n",
    "                lmbda=row[\"lmbda\"],\n",
    "                rate_bpp=row[\"rate_bpp\"],\n",
    "                psnr_db=row[\"psnr_db\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    bds = bd_rates_summary_anchor_name(\n",
    "        metrics, anchor=\"hm\", dataset=dataset, only_latent_rate=False\n",
    "    )\n",
    "    assert len(bds) == 1, \"Expected exactly one BD rate result.\"\n",
    "    return list(bds.values())[0]\n",
    "\n",
    "\n",
    "bd_df = (\n",
    "    finetuning_df.groupby([\"n_itr\", \"seq_name\", \"anchor\"], group_keys=False)\n",
    "    .apply(get_bd_rate_from_df)\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"bd_rate\"})\n",
    ")\n",
    "bd_df[\"num_coolchic_steps\"] = (\n",
    "    bd_df[\"n_itr\"] + flops[\"N-O Cool-chic\"] / flops[\"coolchic_step\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00108542",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(\n",
    "    data=metrics_df[metrics_df[\"dataset\"] == dataset],\n",
    "    x=\"num_coolchic_steps\",\n",
    "    y=\"bd_rate\",\n",
    "    hue=\"method\",\n",
    "    ax=ax,\n",
    ")\n",
    "avg_bd_df = (\n",
    "    bd_df.groupby([\"anchor\", \"n_itr\"])\n",
    "    .agg({\"bd_rate\": \"mean\", \"num_coolchic_steps\": \"mean\"})\n",
    "    .reset_index()\n",
    ")\n",
    "# Add the BD rates from the init points to give an impression of finetuning from the start.\n",
    "avg_bd_df = pd.concat(\n",
    "    [\n",
    "        avg_bd_df,\n",
    "        metrics_df[metrics_df[\"dataset\"] == dataset][\n",
    "            [\"num_coolchic_steps\", \"bd_rate\", \"method\"]\n",
    "        ]\n",
    "        .rename(columns={\"method\": \"anchor\"})\n",
    "        .assign(\n",
    "            anchor=lambda df: df[\"anchor\"]\n",
    "            .apply(lambda x: x.strip(\" (ours)\"))\n",
    "            .apply(lambda x: f\"{x} finetuning\")\n",
    "        )\n",
    "        .assign(n_itr=0),\n",
    "    ]\n",
    ")\n",
    "# Filter out the points in finetuning that are higher than the init points.\n",
    "avg_bd_df = avg_bd_df[avg_bd_df.n_itr != 100]\n",
    "\n",
    "# Need this to match the hue order with the scatter plot.\n",
    "methods_used = [\n",
    "    f\"{name.strip(' (ours)')} finetuning\" for name in metrics_df.method.unique()\n",
    "]\n",
    "sns.lineplot(\n",
    "    data=avg_bd_df,\n",
    "    x=\"num_coolchic_steps\",\n",
    "    y=\"bd_rate\",\n",
    "    hue=\"anchor\",\n",
    "    hue_order=methods_used,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\n",
    "    f\"BD Rate vs. Equivalent number of Cool-chic Steps, averaged over {'CLIC2020' if dataset == 'clic20-pro-valid' else 'Kodak' if dataset == 'kodak' else None} dataset\"\n",
    ")\n",
    "ax.set_xlabel(\"Equivalent number of Cool-chic steps\")\n",
    "ax.set_ylabel(\"average BD Rate (vs. HEVC)\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACs per pixel of a Cool-chic training step.\n",
    "flops[\"coolchic_step\"] / (512**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACs per pixel of a Cool-chic forward pass.\n",
    "{name: flops[name] / (512**2) for name in flops}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645cb79",
   "metadata": {},
   "source": [
    "# Plot 5: extra rate and benefits of adding each part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3c2402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "# from coolchic.eval.results import parse_hypernet_metrics\n",
    "from coolchic.utils.paths import RESULTS_DIR\n",
    "\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"kodak\"\n",
    "baseline_metrics = pd.DataFrame(\n",
    "    [\n",
    "        s.model_dump()\n",
    "        for seq_res in parse_hypernet_metrics(\n",
    "            RESULTS_DIR / \"exps/no-cchic/orange-best/\",\n",
    "            dataset=dataset,\n",
    "            premature=True,\n",
    "        ).values()\n",
    "        for s in seq_res\n",
    "    ]\n",
    ").assign(variant=\"baseline\")\n",
    "nosynth_metrics = pd.DataFrame(\n",
    "    [\n",
    "        s.model_dump()\n",
    "        for seq_res in parse_hypernet_metrics(\n",
    "            RESULTS_DIR / \"eval_no_synth\", dataset=dataset, premature=True\n",
    "        ).values()\n",
    "        for s in seq_res\n",
    "    ]\n",
    ").assign(variant=\"with ARM modulations\")\n",
    "noarm_metrics = pd.DataFrame(\n",
    "    [\n",
    "        s.model_dump()\n",
    "        for seq_res in parse_hypernet_metrics(\n",
    "            RESULTS_DIR / \"eval_no_arm\", dataset=dataset, premature=True\n",
    "        ).values()\n",
    "        for s in seq_res\n",
    "    ]\n",
    ").assign(variant=\"with synthesis modulations\")\n",
    "both_metrics = pd.DataFrame(\n",
    "    [\n",
    "        s.model_dump()\n",
    "        for seq_res in parse_hypernet_metrics(\n",
    "            RESULTS_DIR / \"exps/delta-hn/best-orange/\",\n",
    "            dataset=dataset,\n",
    "            premature=True,\n",
    "        ).values()\n",
    "        for s in seq_res\n",
    "    ]\n",
    ").assign(variant=\"full hypernetwork (ours)\")\n",
    "all_metrics = pd.concat(\n",
    "    [baseline_metrics, nosynth_metrics, noarm_metrics, both_metrics],\n",
    "    ignore_index=True,\n",
    ").sort_values(by=[\"seq_name\", \"lmbda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = all_metrics.groupby([\"variant\", \"lmbda\"]).agg(\n",
    "    {\n",
    "        \"rate_nn_bpp\": \"mean\",\n",
    "        \"psnr_db\": \"mean\",\n",
    "        \"rate_latent_bpp\": \"mean\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# First group the baseline rows by 'lmbda' and subtract them from each group.\n",
    "baseline = agg_df.loc[\"baseline\"]\n",
    "\n",
    "\n",
    "def subtract_baseline(group):\n",
    "    lmbda_val = group.name\n",
    "    base_row = baseline.loc[lmbda_val]\n",
    "    return group - base_row\n",
    "\n",
    "\n",
    "# Apply the subtraction grouped by 'lmbda'\n",
    "diffs = agg_df.groupby(\"lmbda\").apply(subtract_baseline, include_groups=False)\n",
    "diffs = (\n",
    "    diffs.reset_index(level=0, drop=True)\n",
    "    .drop(\"baseline\", level=0)\n",
    "    .reset_index()\n",
    "    .sort_values(\n",
    "        by=[\"variant\", \"lmbda\"],\n",
    "        key=lambda x: x.map(\n",
    "            {\n",
    "                \"with ARM modulations\": 0,\n",
    "                \"with synthesis modulations\": 1,\n",
    "                \"full hypernetwork (ours)\": 2,\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"rate_nn_bpp\": \"rate_nn_bpp_diff\",\n",
    "            \"psnr_db\": \"psnr_db_diff\",\n",
    "            \"rate_latent_bpp\": \"rate_latent_bpp_diff\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fef488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame for seaborn\n",
    "plot_data = diffs.melt(\n",
    "    id_vars=[\"variant\"],\n",
    "    value_vars=[\"rate_nn_bpp_diff\", \"rate_latent_bpp_diff\", \"psnr_db_diff\"],\n",
    "    var_name=\"metric\",\n",
    "    value_name=\"value\",\n",
    ")\n",
    "\n",
    "# Separate data for the two axes\n",
    "bpp_data = plot_data[plot_data[\"metric\"].str.contains(\"bpp\")]\n",
    "psnr_data = plot_data[plot_data[\"metric\"].str.contains(\"psnr\")]\n",
    "\n",
    "# Pivot the data and remove the baseline variant (its diff is always 0)\n",
    "diffs_pivot = diffs.set_index(\"variant\").loc[\n",
    "    [\"with ARM modulations\", \"with synthesis modulations\", \"full hypernetwork (ours)\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ablation(diff_pivot_df: pd.DataFrame, lmbda_val: float | None = None) -> None:\n",
    "    # --- 4. Create the Plot ---\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 3))\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # --- Bar properties ---\n",
    "    variants = diff_pivot_df.index\n",
    "    x_pos = np.arange(len(variants))  # The label locations [0, 1, 2]\n",
    "    bar_width = 0.10  # Set the desired width of the bars\n",
    "    offsets = np.array([-bar_width, 0, bar_width])  # Offsets for the three bars\n",
    "\n",
    "    # Define colors\n",
    "    # Dutch field and blue to yellow color palettes\n",
    "    # https://www.heavy.ai/blog/12-color-palettes-for-telling-better-stories-with-your-data\n",
    "    bpp1_color = \"#115f9a\"\n",
    "    bpp2_color = \"#22a7f0\"\n",
    "    psnr_color = \"#e60049\"  # A slightly different red\n",
    "\n",
    "    # --- Plotting the bars manually ---\n",
    "    # Plot BPP stems on ax1\n",
    "    markerline, stemlines, baseline = ax1.stem(\n",
    "        x_pos + offsets[0], diff_pivot_df[\"rate_nn_bpp_diff\"]\n",
    "    )\n",
    "    plt.setp(markerline, marker=\"o\", markersize=8, color=bpp1_color)\n",
    "    plt.setp(stemlines, color=bpp1_color)\n",
    "    plt.setp(baseline, visible=False)\n",
    "\n",
    "    markerline, stemlines, baseline = ax1.stem(\n",
    "        x_pos + offsets[1], diff_pivot_df[\"rate_latent_bpp_diff\"]\n",
    "    )\n",
    "    plt.setp(markerline, marker=\"o\", markersize=8, color=bpp2_color)\n",
    "    plt.setp(stemlines, color=bpp2_color)\n",
    "    plt.setp(baseline, visible=False)\n",
    "\n",
    "    # Plot PSNR stems on ax2\n",
    "    markerline, stemlines, baseline = ax2.stem(\n",
    "        x_pos + offsets[2], diff_pivot_df[\"psnr_db_diff\"]\n",
    "    )\n",
    "    plt.setp(markerline, marker=\"o\", markersize=8, color=psnr_color)\n",
    "    plt.setp(stemlines, color=psnr_color)\n",
    "    plt.setp(baseline, visible=False)\n",
    "\n",
    "    # --- 5. Customize the Plot ---\n",
    "    ax1.set_title(\n",
    "        f\"Ablation Study: Metric changes with respect to N-O Cool-chic. Lambda: {lmbda_val if lmbda_val is not None else 'all'}\",\n",
    "        fontsize=12,\n",
    "        pad=10,\n",
    "    )\n",
    "    ax1.set_xlabel(\"Model Variant\", fontsize=10)\n",
    "    ax1.set_ylabel(\n",
    "        \"$\\\\Delta$ bpp ($\\\\leftarrow$ better)\", fontsize=10, color=bpp1_color\n",
    "    )\n",
    "    ax2.set_ylabel(\n",
    "        \"$\\\\Delta$ PSNR (dB) ($\\\\rightarrow$ better)\", fontsize=10, color=psnr_color\n",
    "    )\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(variants, fontsize=8)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=bpp1_color)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=psnr_color)\n",
    "    ax2.spines[\"left\"].set_color(bpp1_color)\n",
    "    ax2.spines[\"right\"].set_color(psnr_color)\n",
    "\n",
    "    # --- 6. Align the zero-lines of the two axes (The Fix) ---\n",
    "    # Get the current limits\n",
    "    y1_min, y1_max = ax1.get_ylim()\n",
    "    y2_min, y2_max = ax2.get_ylim()\n",
    "\n",
    "    # Calculate the largest absolute value for each axis\n",
    "    abs_max1 = max(abs(y1_min), abs(y1_max))\n",
    "    abs_max2 = max(abs(y2_min), abs(y2_max))\n",
    "\n",
    "    # Set symmetrical limits on both axes with a 10% margin\n",
    "    ax1.set_ylim(-abs_max1 * 1.1, abs_max1 * 1.1)\n",
    "    ax2.set_ylim(-abs_max2 * 1.1, abs_max2 * 1.1)\n",
    "\n",
    "    # Now that they are aligned, one zero-line is sufficient\n",
    "    ax1.axhline(0, color=\"black\", linewidth=1.0, linestyle=\"--\", zorder=0)\n",
    "\n",
    "    # --- 6. Create a Manual Legend ---\n",
    "    legend_elements = [\n",
    "        Patch(\n",
    "            facecolor=bpp1_color,\n",
    "            edgecolor=\"black\",\n",
    "            label=\"$\\\\Delta$ Modulation rate (bpp, low is better)\",\n",
    "        ),\n",
    "        Patch(\n",
    "            facecolor=bpp2_color,\n",
    "            edgecolor=\"black\",\n",
    "            label=\"$\\\\Delta$ Latent rate (bpp, low is better)\",\n",
    "        ),\n",
    "        Patch(\n",
    "            facecolor=psnr_color,\n",
    "            edgecolor=\"black\",\n",
    "            label=\"$\\\\Delta$ PSNR (dB, high is better)\",\n",
    "        ),\n",
    "    ]\n",
    "    ax1.legend(\n",
    "        handles=legend_elements,\n",
    "        loc=\"lower center\",\n",
    "        # bbox_to_anchor=(0.5, 0.15),\n",
    "        # ncol=3,\n",
    "        fancybox=True,\n",
    "        shadow=False,\n",
    "        fontsize=7,\n",
    "    )\n",
    "\n",
    "    # Adjust axis limits to prevent bars from touching the edges\n",
    "    ax1_min, ax1_max = ax1.get_ylim()\n",
    "    ax1.set_ylim(ax1_min * 1.15, ax1_max * 1.15)\n",
    "    ax2_min, ax2_max = ax2.get_ylim()\n",
    "    ax2.set_ylim(ax2_min * 1.15, ax2_max * 1.15)\n",
    "\n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to make room for the title\n",
    "    plt.tight_layout()  # Adjust layout to make room for the title\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lmbd in diffs_pivot.lmbda.unique():\n",
    "    plot_ablation(diffs_pivot[diffs_pivot.lmbda == lmbd], lmbda_val=lmbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but in a table\n",
    "for lmbd in diffs_pivot.lmbda.unique():\n",
    "    print(f\"Lambda: {lmbd}\")\n",
    "    print(\n",
    "        diffs_pivot.loc[diffs_pivot.lmbda == lmbd][\n",
    "            [\"rate_nn_bpp_diff\", \"rate_latent_bpp_diff\", \"psnr_db_diff\"]\n",
    "        ].reset_index()\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coolchic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
