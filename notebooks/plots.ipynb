{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "180f935d",
   "metadata": {},
   "source": [
    "# How to use this for just plotting\n",
    "In case you haven't worked with the repo but want to get these plots, there are some preliminary steps you'll need to follow.\n",
    "1. For now, clone the whole repo (`git clone https://github.com/pepborrell/cool-chic.git`). It takes a while and it's a little heavy but it will make things so much easier.\n",
    "2. Create the environment to run all code in the repo with `uv run python`. If you don't have uv, install it with `curl -LsSf https://astral.sh/uv/install.sh | sh` (or `pip install uv`). Use that environment to run this notebook.\n",
    "3. Theoretically, all necessary data is already in the repo.\n",
    "\n",
    "You can now plot all you need, it should work."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940b90ad",
   "metadata": {},
   "source": [
    "# Plot 1: RD plots for avgs in a dataset and some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9721d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from typing import Literal\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "from coolchic.eval.bd_rate import bd_rates_summary_anchor_name\n",
    "from coolchic.eval.hypernet import (\n",
    "    get_hypernet_flops,\n",
    "    plot_hypernet_rd,\n",
    "    plot_hypernet_rd_avg,\n",
    ")\n",
    "from coolchic.eval.results import SummaryEncodingMetrics, parse_hypernet_metrics\n",
    "from coolchic.hypernet.hypernet import DeltaWholeNet, NOWholeNet\n",
    "from coolchic.utils.paths import COOLCHIC_REPO_ROOT, DATA_DIR, RESULTS_DIR\n",
    "\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\")\n",
    "plt.rcParams[\"figure.dpi\"] = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999e20e9-7608-441e-980a-d25e8ff17139",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d11a9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_path = RESULTS_DIR / \"exps/delta-hn/longer-ups-best-orange/\"\n",
    "compare_no_path = RESULTS_DIR / \"exps/no-cchic/orange-best/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0596be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rd_plots_from_dataset(dataset: Literal[\"kodak\", \"clic20-pro-valid\"]) -> None:\n",
    "    import pandas as pd\n",
    "\n",
    "    metrics = parse_hypernet_metrics(sweep_path, dataset=dataset, premature=True)\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                [s.model_dump() for seq_res in metrics.values() for s in seq_res]\n",
    "            ).assign(anchor=\"hypernet (ours)\"),\n",
    "            pd.DataFrame(  # For comparison with no hypernet.\n",
    "                [\n",
    "                    s.model_dump()\n",
    "                    for seq_res in parse_hypernet_metrics(\n",
    "                        compare_no_path, dataset, premature=True\n",
    "                    ).values()\n",
    "                    for s in seq_res\n",
    "                ]\n",
    "            ).assign(anchor=\"n-o cool-chic\"),\n",
    "        ],\n",
    "    ).sort_values(by=[\"seq_name\", \"lmbda\"])  # So plots come out nice and in order.\n",
    "\n",
    "    plot_hypernet_rd_avg(df, dataset=dataset)\n",
    "\n",
    "    all_images = sorted(list((DATA_DIR / dataset).glob(\"*.png\")), key=lambda x: x.stem)\n",
    "    for img in all_images[:5]:\n",
    "        seq_name = img.stem\n",
    "        plot_hypernet_rd(seq_name, df, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09de600",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rd_plots_from_dataset_print(dataset: Literal[\"kodak\", \"clic20-pro-valid\"]) -> None:\n",
    "    import pandas as pd\n",
    "\n",
    "    metrics = parse_hypernet_metrics(sweep_path, dataset=dataset, premature=True)\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            pd.DataFrame(\n",
    "                [s.model_dump() for seq_res in metrics.values() for s in seq_res]\n",
    "            ).assign(anchor=\"hypernet (ours)\"),\n",
    "            pd.DataFrame(  # For comparison with no hypernet.\n",
    "                [\n",
    "                    s.model_dump()\n",
    "                    for seq_res in parse_hypernet_metrics(\n",
    "                        compare_no_path, dataset, premature=True\n",
    "                    ).values()\n",
    "                    for s in seq_res\n",
    "                ]\n",
    "            ).assign(anchor=\"n-o cool-chic\"),\n",
    "        ],\n",
    "    ).sort_values(by=[\"seq_name\", \"lmbda\"])  # So plots come out nice and in order.\n",
    "\n",
    "    from pathlib import Path\n",
    "    from typing import Any\n",
    "\n",
    "    def split_row(row: str) -> list[Any]:\n",
    "        split_char = \" \"\n",
    "        if \"\\t\" in row:\n",
    "            split_char = \"\\t\"\n",
    "        return [elem.strip() for elem in row.split(split_char) if elem != \"\"]\n",
    "\n",
    "    def parse_result_summary(\n",
    "        summary_file: Path,\n",
    "    ) -> dict[str, list[SummaryEncodingMetrics]]:\n",
    "        with open(summary_file, \"r\") as f:\n",
    "            metric_names = split_row(f.readline().strip())\n",
    "            raw_metrics = f.readlines()\n",
    "        results = defaultdict(list)\n",
    "        for line in raw_metrics:\n",
    "            line_metrics = {n: v for n, v in zip(metric_names, split_row(line))}\n",
    "            results[line_metrics[\"seq_name\"]].append(\n",
    "                SummaryEncodingMetrics(**line_metrics)\n",
    "            )\n",
    "        return dict(results)\n",
    "\n",
    "    def result_summary_to_df(summary_path: Path) -> pd.DataFrame:\n",
    "        summaries = parse_result_summary(summary_path)\n",
    "        all_data = []\n",
    "        for seq_name in summaries:\n",
    "            all_data.extend([s.model_dump() for s in summaries[seq_name]])\n",
    "        return pd.DataFrame(all_data)\n",
    "\n",
    "    def compare_dataset_res(results: pd.DataFrame, dataset) -> pd.DataFrame:\n",
    "        from coolchic.utils.paths import ALL_ANCHORS\n",
    "\n",
    "        res_sums = []\n",
    "        for anchor, results_path in ALL_ANCHORS[dataset].items():\n",
    "            df = result_summary_to_df(results_path)\n",
    "            df[\"anchor\"] = anchor\n",
    "            # delete columns that are all nan\n",
    "            df = df.dropna(axis=1, how=\"all\")\n",
    "            res_sums.append(df)\n",
    "\n",
    "        assert \"anchor\" in results.columns, \"Anchor column not found in results\"\n",
    "        res_sums.append(results)\n",
    "        all_df = pd.concat(res_sums)\n",
    "        return all_df\n",
    "\n",
    "    def plot_hypernet_rd_avg(results: pd.DataFrame, dataset):\n",
    "        \"\"\"Plots the average RD plot for the whole dataset in results.\"\"\"\n",
    "        all_df = compare_dataset_res(results, dataset)\n",
    "        mean_df = (\n",
    "            all_df.groupby([\"anchor\", \"lmbda\"])\n",
    "            .agg({\"rate_bpp\": \"mean\", \"psnr_db\": \"mean\"})\n",
    "            .reset_index()\n",
    "        ).sort_values(by=[\"anchor\", \"rate_bpp\"])\n",
    "        with pd.option_context(\"display.max_rows\", None, \"display.max_columns\", None):\n",
    "            print(mean_df)\n",
    "        # Assuming mean_df is your DataFrame with columns: anchor, rate_bpp, psnr_db\n",
    "        anchors = mean_df[\"anchor\"].unique()\n",
    "\n",
    "        for anchor in anchors:\n",
    "            df_anchor = mean_df[mean_df[\"anchor\"] == anchor][[\"rate_bpp\", \"psnr_db\"]]\n",
    "            df_anchor.to_csv(\n",
    "                f\"{anchor.replace(' ', '_').replace('(', '').replace(')', '')}.csv\",\n",
    "                index=False,\n",
    "            )\n",
    "\n",
    "        fig, ax = plt.subplots()\n",
    "        sns.lineplot(\n",
    "            mean_df,\n",
    "            x=\"rate_bpp\",\n",
    "            y=\"psnr_db\",\n",
    "            hue=\"anchor\",\n",
    "            marker=\"o\",\n",
    "            markeredgecolor=\"none\",\n",
    "            ax=ax,\n",
    "            sort=False,\n",
    "        )\n",
    "        ax.set_title(\n",
    "            f\"Average RD curve. Dataset: {'CLIC2020' if dataset == 'clic20-pro-valid' else 'kodak'}\"\n",
    "        )\n",
    "        ax.set_xlabel(\"Rate (bpp)\")\n",
    "        ax.set_ylabel(\"PSNR (dB)\")\n",
    "        return fig, ax\n",
    "\n",
    "    fig, ax = plot_hypernet_rd_avg(df, dataset=dataset)\n",
    "    plt.savefig(\"kodak.png\")\n",
    "    # all_images = sorted(list((DATA_DIR / dataset).glob(\"*.png\")), key=lambda x: x.stem)\n",
    "    # for img in all_images[:5]:\n",
    "    #     seq_name = img.stem\n",
    "    #     plot_hypernet_rd(seq_name, df, dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8e58b0-97a2-444c-89ab-4ae7bee54080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = rd_plots_from_dataset(\"kodak\")  # get data and run existing plot code if needed\n",
    "df = rd_plots_from_dataset_print(\"clic20-pro-valid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c04df9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_plots_from_dataset(\"clic20-pro-valid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c2d8de",
   "metadata": {},
   "source": [
    "# Plot 2: flops vs BD-rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a524fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# from coolchic.eval.hypernet import get_hypernet_flops\n",
    "# from coolchic.hypernet.hypernet import DeltaWholeNet, NOWholeNet\n",
    "\n",
    "sns.set_theme(context=\"notebook\", style=\"whitegrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5f2366",
   "metadata": {},
   "outputs": [],
   "source": [
    "flops = {\n",
    "    \"coolchic\": (\n",
    "        coolchic_fwd := get_hypernet_flops(DeltaWholeNet, get_coolchic_flops=True)\n",
    "    ),\n",
    "    \"coolchic_step\": 3 * coolchic_fwd,\n",
    "    \"N-O Cool-chic\": get_hypernet_flops(NOWholeNet),\n",
    "    \"Hypernet (ours)\": get_hypernet_flops(DeltaWholeNet),\n",
    "}\n",
    "\n",
    "bd_rates = {\n",
    "    \"kodak\": {\n",
    "        \"N-O Cool-chic\": 0,\n",
    "        \"Hypernet (ours)\": 0,\n",
    "    },\n",
    "    \"clic20-pro-valid\": {\n",
    "        \"N-O Cool-chic\": 0,\n",
    "        \"Hypernet (ours)\": 0,\n",
    "    },\n",
    "}\n",
    "\n",
    "metrics_dfg = pd.DataFrame(\n",
    "    [\n",
    "        (dataset, method, bd_rate, flops[method])\n",
    "        for dataset, bd_rates in bd_rates.items()\n",
    "        for method, bd_rate in bd_rates.items()\n",
    "    ],\n",
    "    columns=[\"dataset\", \"method\", \"bd_rate\", \"flops\"],\n",
    ")\n",
    "metrics_dfg[\"num_coolchic_steps\"] = metrics_dfg[\"flops\"] / flops[\"coolchic_step\"]\n",
    "metrics_dfg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b075013",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(\n",
    "    data=metrics_dfg[metrics_dfg[\"dataset\"] == \"clic20-pro-valid\"],\n",
    "    x=\"num_coolchic_steps\",\n",
    "    y=\"bd_rate\",\n",
    "    hue=\"method\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\"BD Rate vs. Equivalent number of Cool-chic Steps, CLIC20 dataset\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56551e52",
   "metadata": {},
   "source": [
    "# Plot 4: show bd rate vs flops as training progresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fae6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "flops = {\n",
    "    \"coolchic\": (\n",
    "        coolchic_fwd := get_hypernet_flops(DeltaWholeNet, get_coolchic_flops=True)\n",
    "    ),\n",
    "    \"coolchic_step\": 3 * coolchic_fwd,\n",
    "    \"N-O Cool-chic\": get_hypernet_flops(NOWholeNet),\n",
    "    \"Hypernet (ours)\": get_hypernet_flops(DeltaWholeNet),\n",
    "}\n",
    "\n",
    "bd_rates = {\n",
    "    \"kodak\": {\n",
    "        \"N-O Cool-chic\": 24.4463703313217,\n",
    "        \"Hypernet (ours)\": 23.089282405055148,\n",
    "    },\n",
    "    \"clic20-pro-valid\": {\n",
    "        \"N-O Cool-chic\": 19.338375256558283,\n",
    "        \"Hypernet (ours)\": 14.948009862621655,\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "metrics_df = pd.DataFrame(\n",
    "    [\n",
    "        (dataset, method, bd_rate, flops[method])\n",
    "        for dataset, bd_rates in bd_rates.items()\n",
    "        for method, bd_rate in bd_rates.items()\n",
    "    ],\n",
    "    columns=[\"dataset\", \"method\", \"bd_rate\", \"flops\"],\n",
    ")\n",
    "metrics_df[\"num_coolchic_steps\"] = metrics_df[\"flops\"] / flops[\"coolchic_step\"]\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ffa0235",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"clic20-pro-valid\"\n",
    "# dataset = \"kodak\"\n",
    "CONFIG_NUM_TO_LMBDA = {\n",
    "    \"00\": 0.0001,\n",
    "    \"01\": 0.0002,\n",
    "    \"02\": 0.0004,\n",
    "    \"03\": 0.001,\n",
    "    \"04\": 0.004,\n",
    "    \"05\": 0.02,\n",
    "}\n",
    "# We filter out the methods that are not interesting for our analysis.\n",
    "interesting_methods = [\"orange-best\", \"longer-ups-best-orange\"]\n",
    "\n",
    "finetuning_dir = RESULTS_DIR / \"finetuning\" / dataset\n",
    "finetuning_df = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(file)\n",
    "        for file in finetuning_dir.glob(\"**/*.csv\")\n",
    "        if file.parent.stem in interesting_methods\n",
    "    ]\n",
    ")\n",
    "finetuning_df = finetuning_df.reset_index(drop=True)\n",
    "finetuning_df[\"anchor\"] = finetuning_df[\"anchor\"].apply(\n",
    "    lambda x: \"N-O Cool-chic finetuning\" if \"NO\" in x else \"Hypernet finetuning\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e0aa6c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bd_rate_from_df(df: pd.DataFrame) -> float:\n",
    "    metrics = defaultdict(list)\n",
    "    for _, row in df.iterrows():\n",
    "        assert \"seq_name\" in row, \"seq_name column is missing in the DataFrame\"\n",
    "        metrics[row[\"seq_name\"]].append(\n",
    "            SummaryEncodingMetrics(\n",
    "                seq_name=row[\"seq_name\"],\n",
    "                lmbda=row[\"lmbda\"],\n",
    "                rate_bpp=row[\"rate_bpp\"],\n",
    "                psnr_db=row[\"psnr_db\"],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    bds = bd_rates_summary_anchor_name(\n",
    "        metrics, anchor=\"hm\", dataset=dataset, only_latent_rate=False\n",
    "    )\n",
    "    assert len(bds) == 1, \"Expected exactly one BD rate result.\"\n",
    "    return list(bds.values())[0]\n",
    "\n",
    "\n",
    "bd_df = (\n",
    "    finetuning_df.groupby([\"n_itr\", \"seq_name\", \"anchor\"], group_keys=False)\n",
    "    .apply(get_bd_rate_from_df)\n",
    "    .reset_index()\n",
    "    .rename(columns={0: \"bd_rate\"})\n",
    ")\n",
    "bd_df[\"num_coolchic_steps\"] = (\n",
    "    bd_df[\"n_itr\"] + flops[\"N-O Cool-chic\"] / flops[\"coolchic_step\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00108542",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "sns.scatterplot(\n",
    "    data=metrics_df[metrics_df[\"dataset\"] == dataset],\n",
    "    x=\"num_coolchic_steps\",\n",
    "    y=\"bd_rate\",\n",
    "    hue=\"method\",\n",
    "    ax=ax,\n",
    ")\n",
    "avg_bd_df = (\n",
    "    bd_df.groupby([\"anchor\", \"n_itr\"])\n",
    "    .agg({\"bd_rate\": \"mean\", \"num_coolchic_steps\": \"mean\"})\n",
    "    .reset_index()\n",
    ")\n",
    "# Add the BD rates from the init points to give an impression of finetuning from the start.\n",
    "avg_bd_df = pd.concat(\n",
    "    [\n",
    "        avg_bd_df,\n",
    "        metrics_df[metrics_df[\"dataset\"] == dataset][\n",
    "            [\"num_coolchic_steps\", \"bd_rate\", \"method\"]\n",
    "        ]\n",
    "        .rename(columns={\"method\": \"anchor\"})\n",
    "        .assign(\n",
    "            anchor=lambda df: df[\"anchor\"]\n",
    "            .apply(lambda x: x.strip(\" (ours)\"))\n",
    "            .apply(lambda x: f\"{x} finetuning\")\n",
    "        )\n",
    "        .assign(n_itr=0),\n",
    "    ]\n",
    ")\n",
    "# Filter out the points in finetuning that are higher than the init points.\n",
    "avg_bd_df = avg_bd_df[avg_bd_df.n_itr != 100]\n",
    "\n",
    "# Need this to match the hue order with the scatter plot.\n",
    "methods_used = [\n",
    "    f\"{name.strip(' (ours)')} finetuning\" for name in metrics_df.method.unique()\n",
    "]\n",
    "sns.lineplot(\n",
    "    data=avg_bd_df,\n",
    "    x=\"num_coolchic_steps\",\n",
    "    y=\"bd_rate\",\n",
    "    hue=\"anchor\",\n",
    "    hue_order=methods_used,\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_title(\n",
    "    f\"BD Rate vs. Equivalent number of Cool-chic Steps, averaged over {'CLIC2020' if dataset == 'clic20-pro-valid' else 'Kodak' if dataset == 'kodak' else None} dataset\"\n",
    ")\n",
    "ax.set_xlabel(\"Equivalent number of Cool-chic steps\")\n",
    "ax.set_ylabel(\"average BD Rate (vs. HEVC)\")\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ae4a2e-21a5-4ac7-a32a-6961cf0e0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Scatter plot of raw data\n",
    "scatter_data = metrics_df[metrics_df[\"dataset\"] == dataset]\n",
    "sns.scatterplot(\n",
    "    data=scatter_data,\n",
    "    x=\"num_coolchic_steps\",\n",
    "    y=\"bd_rate\",\n",
    "    hue=\"method\",\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Print scatter plot data\n",
    "print(\"=== Scatter Data ===\")\n",
    "print(scatter_data[[\"num_coolchic_steps\", \"bd_rate\", \"method\"]])\n",
    "\n",
    "# Create averaged lineplot data\n",
    "avg_bd_df = (\n",
    "    bd_df.groupby([\"anchor\", \"n_itr\"])\n",
    "    .agg({\"bd_rate\": \"mean\", \"num_coolchic_steps\": \"mean\"})\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Add initial points (n_itr = 0) to the average data for visualizing finetuning starting points\n",
    "init_points = (\n",
    "    metrics_df[metrics_df[\"dataset\"] == dataset][\n",
    "        [\"num_coolchic_steps\", \"bd_rate\", \"method\"]\n",
    "    ]\n",
    "    .rename(columns={\"method\": \"anchor\"})\n",
    "    .assign(\n",
    "        anchor=lambda df: df[\"anchor\"]\n",
    "        .apply(lambda x: x.strip(\" (ours)\"))\n",
    "        .apply(lambda x: f\"{x} finetuning\"),\n",
    "        n_itr=0,\n",
    "    )\n",
    ")\n",
    "\n",
    "# Concatenate init points to averaged data\n",
    "avg_bd_df = pd.concat([avg_bd_df, init_points])\n",
    "\n",
    "# Filter out final iteration points if needed\n",
    "avg_bd_df = avg_bd_df[avg_bd_df.n_itr != 100]\n",
    "\n",
    "# Define hue order to match scatter plot\n",
    "methods_used = [\n",
    "    f\"{name.strip(' (ours)')} finetuning\" for name in metrics_df.method.unique()\n",
    "]\n",
    "\n",
    "# Plot average BD rate over steps\n",
    "sns.lineplot(\n",
    "    data=avg_bd_df,\n",
    "    x=\"num_coolchic_steps\",\n",
    "    y=\"bd_rate\",\n",
    "    hue=\"anchor\",\n",
    "    hue_order=methods_used,\n",
    "    ax=ax,\n",
    ")\n",
    "\n",
    "# Print line plot data\n",
    "print(\"=== Line Data ===\")\n",
    "line_df = avg_bd_df.assign(mac_pixel=avg_bd_df[\"num_coolchic_steps\"] * 4290)[\n",
    "    [\"num_coolchic_steps\", \"mac_pixel\", \"bd_rate\", \"n_itr\", \"anchor\"]\n",
    "]\n",
    "print(line_df.columns.tolist())\n",
    "for row in line_df.iterrows():\n",
    "    # Print each row as a space-separated string\n",
    "    print(\" \".join(map(str, row[1].values)))\n",
    "\n",
    "# Titles and labels\n",
    "ax.set_title(\n",
    "    f\"BD Rate vs. Equivalent number of Cool-chic Steps, averaged over {'CLIC2020' if dataset == 'clic20-pro-valid' else 'Kodak' if dataset == 'kodak' else None} dataset\"\n",
    ")\n",
    "ax.set_xlabel(\"Equivalent number of Cool-chic steps\")\n",
    "ax.set_ylabel(\"average BD Rate (vs. HEVC)\")\n",
    "\n",
    "# Style\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9453909b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACs per pixel of a Cool-chic training step.\n",
    "flops[\"coolchic_step\"] / (512**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961e53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MACs per pixel of a Cool-chic forward pass.\n",
    "{name: flops[name] / (512**2) for name in flops}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0645cb79",
   "metadata": {},
   "source": [
    "# Plot 5: extra rate and benefits of adding each part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c434ea39",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"clic20-pro-valid\"\n",
    "ablation_dir = COOLCHIC_REPO_ROOT / \"switch-ablation-exps\"\n",
    "\n",
    "all_ablation_metrics = {}\n",
    "for dir in ablation_dir.iterdir():\n",
    "    parts = dir.stem.split(\"_\")\n",
    "    dir_metrics = pd.DataFrame(\n",
    "        [\n",
    "            s.model_dump()\n",
    "            for seq_res in parse_hypernet_metrics(dir, dataset=dataset).values()\n",
    "            for s in seq_res\n",
    "        ]\n",
    "    ).assign(variant=dir.name if dir.name != \"none\" else \"baseline\")\n",
    "    all_ablation_metrics[dir.name] = dir_metrics\n",
    "\n",
    "all_metrics = pd.concat(\n",
    "    all_ablation_metrics.values(),\n",
    "    ignore_index=True,\n",
    ").sort_values(by=[\"seq_name\", \"lmbda\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbb419e",
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_df = all_metrics.groupby([\"variant\", \"lmbda\"]).agg(\n",
    "    {\n",
    "        \"rate_nn_bpp\": \"mean\",\n",
    "        \"psnr_db\": \"mean\",\n",
    "        \"rate_latent_bpp\": \"mean\",\n",
    "    }\n",
    ")\n",
    "\n",
    "# First group the baseline rows by 'lmbda' and subtract them from each group.\n",
    "baseline = agg_df.loc[\"baseline\"]\n",
    "\n",
    "\n",
    "def subtract_baseline(group):\n",
    "    lmbda_val = group.name\n",
    "    base_row = baseline.loc[lmbda_val]\n",
    "    return group - base_row\n",
    "\n",
    "\n",
    "# Apply the subtraction grouped by 'lmbda'\n",
    "diffs = agg_df.groupby(\"lmbda\").apply(subtract_baseline, include_groups=False)\n",
    "diffs = (\n",
    "    diffs.reset_index(level=0, drop=True)\n",
    "    .drop(\"baseline\", level=0)\n",
    "    .reset_index()\n",
    "    .sort_values(\n",
    "        by=[\"variant\", \"lmbda\"],\n",
    "        key=lambda x: x.map(\n",
    "            {\n",
    "                \"with ARM modulations\": 0,\n",
    "                \"with synthesis modulations\": 1,\n",
    "                \"full hypernetwork (ours)\": 2,\n",
    "            }\n",
    "        ),\n",
    "    )\n",
    "    .rename(\n",
    "        columns={\n",
    "            \"rate_nn_bpp\": \"rate_nn_bpp_diff\",\n",
    "            \"psnr_db\": \"psnr_db_diff\",\n",
    "            \"rate_latent_bpp\": \"rate_latent_bpp_diff\",\n",
    "        }\n",
    "    )\n",
    ")\n",
    "diffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fef488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the DataFrame for seaborn\n",
    "plot_data = diffs.melt(\n",
    "    id_vars=[\"variant\"],\n",
    "    value_vars=[\"rate_nn_bpp_diff\", \"rate_latent_bpp_diff\", \"psnr_db_diff\"],\n",
    "    var_name=\"metric\",\n",
    "    value_name=\"value\",\n",
    ")\n",
    "\n",
    "# Separate data for the two axes\n",
    "bpp_data = plot_data[plot_data[\"metric\"].str.contains(\"bpp\")]\n",
    "psnr_data = plot_data[plot_data[\"metric\"].str.contains(\"psnr\")]\n",
    "\n",
    "# Pivot the data and remove the baseline variant (its diff is always 0)\n",
    "diffs_pivot = diffs.set_index(\"variant\").loc[\n",
    "    [\"with ARM modulations\", \"with synthesis modulations\", \"full hypernetwork (ours)\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8af2aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ablation(diff_pivot_df: pd.DataFrame, lmbda_val: float | None = None) -> None:\n",
    "    print(\"\\n--- LaTeX Table ---\")\n",
    "    print(\n",
    "        diff_pivot_df.to_latex(\n",
    "            float_format=\"%.4f\", column_format=\"lccc\", bold_rows=True\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # --- 4. Create the Plot ---\n",
    "    fig, ax1 = plt.subplots(figsize=(6, 3))\n",
    "    ax2 = ax1.twinx()\n",
    "\n",
    "    # --- Bar properties ---\n",
    "    variants = diff_pivot_df.index\n",
    "    x_pos = np.arange(len(variants))  # The label locations [0, 1, 2]\n",
    "    bar_width = 0.10  # Set the desired width of the bars\n",
    "    offsets = np.array([-bar_width, 0, bar_width])  # Offsets for the three bars\n",
    "\n",
    "    # Define colors\n",
    "    # Dutch field and blue to yellow color palettes\n",
    "    # https://www.heavy.ai/blog/12-color-palettes-for-telling-better-stories-with-your-data\n",
    "    bpp1_color = \"#115f9a\"\n",
    "    bpp2_color = \"#22a7f0\"\n",
    "    psnr_color = \"#e60049\"  # A slightly different red\n",
    "\n",
    "    # --- Plotting the bars manually ---\n",
    "    # Plot BPP stems on ax1\n",
    "    markerline, stemlines, baseline = ax1.stem(\n",
    "        x_pos + offsets[0], diff_pivot_df[\"rate_nn_bpp_diff\"]\n",
    "    )\n",
    "    plt.setp(markerline, marker=\"o\", markersize=8, color=bpp1_color)\n",
    "    plt.setp(stemlines, color=bpp1_color)\n",
    "    plt.setp(baseline, visible=False)\n",
    "\n",
    "    markerline, stemlines, baseline = ax1.stem(\n",
    "        x_pos + offsets[1], diff_pivot_df[\"rate_latent_bpp_diff\"]\n",
    "    )\n",
    "    plt.setp(markerline, marker=\"o\", markersize=8, color=bpp2_color)\n",
    "    plt.setp(stemlines, color=bpp2_color)\n",
    "    plt.setp(baseline, visible=False)\n",
    "\n",
    "    # Plot PSNR stems on ax2\n",
    "    markerline, stemlines, baseline = ax2.stem(\n",
    "        x_pos + offsets[2], diff_pivot_df[\"psnr_db_diff\"]\n",
    "    )\n",
    "    plt.setp(markerline, marker=\"o\", markersize=8, color=psnr_color)\n",
    "    plt.setp(stemlines, color=psnr_color)\n",
    "    plt.setp(baseline, visible=False)\n",
    "\n",
    "    # --- 5. Customize the Plot ---\n",
    "    ax1.set_title(\n",
    "        f\"Ablation Study: Metric changes with respect to N-O Cool-chic. Lambda: {lmbda_val if lmbda_val is not None else 'all'}\",\n",
    "        fontsize=12,\n",
    "        pad=10,\n",
    "    )\n",
    "    ax1.set_xlabel(\"Model Variant\", fontsize=10)\n",
    "    ax1.set_ylabel(\n",
    "        \"$\\\\Delta$ bpp ($\\\\leftarrow$ better)\", fontsize=10, color=bpp1_color\n",
    "    )\n",
    "    ax2.set_ylabel(\n",
    "        \"$\\\\Delta$ PSNR (dB) ($\\\\rightarrow$ better)\", fontsize=10, color=psnr_color\n",
    "    )\n",
    "    ax1.set_xticks(x_pos)\n",
    "    ax1.set_xticklabels(variants, fontsize=8)\n",
    "    ax1.tick_params(axis=\"y\", labelcolor=bpp1_color)\n",
    "    ax2.tick_params(axis=\"y\", labelcolor=psnr_color)\n",
    "    ax2.spines[\"left\"].set_color(bpp1_color)\n",
    "    ax2.spines[\"right\"].set_color(psnr_color)\n",
    "\n",
    "    # --- 6. Align the zero-lines of the two axes (The Fix) ---\n",
    "    # Get the current limits\n",
    "    y1_min, y1_max = ax1.get_ylim()\n",
    "    y2_min, y2_max = ax2.get_ylim()\n",
    "\n",
    "    # Calculate the largest absolute value for each axis\n",
    "    abs_max1 = max(abs(y1_min), abs(y1_max))\n",
    "    abs_max2 = max(abs(y2_min), abs(y2_max))\n",
    "\n",
    "    # Set symmetrical limits on both axes with a 10% margin\n",
    "    ax1.set_ylim(-abs_max1 * 1.1, abs_max1 * 1.1)\n",
    "    ax2.set_ylim(-abs_max2 * 1.1, abs_max2 * 1.1)\n",
    "\n",
    "    # Now that they are aligned, one zero-line is sufficient\n",
    "    ax1.axhline(0, color=\"black\", linewidth=1.0, linestyle=\"--\", zorder=0)\n",
    "\n",
    "    # --- 6. Create a Manual Legend ---\n",
    "    legend_elements = [\n",
    "        Patch(\n",
    "            facecolor=bpp1_color,\n",
    "            edgecolor=\"black\",\n",
    "            label=\"$\\\\Delta$ Modulation rate (bpp, low is better)\",\n",
    "        ),\n",
    "        Patch(\n",
    "            facecolor=bpp2_color,\n",
    "            edgecolor=\"black\",\n",
    "            label=\"$\\\\Delta$ Latent rate (bpp, low is better)\",\n",
    "        ),\n",
    "        Patch(\n",
    "            facecolor=psnr_color,\n",
    "            edgecolor=\"black\",\n",
    "            label=\"$\\\\Delta$ PSNR (dB, high is better)\",\n",
    "        ),\n",
    "    ]\n",
    "    ax1.legend(\n",
    "        handles=legend_elements,\n",
    "        loc=\"lower center\",\n",
    "        # bbox_to_anchor=(0.5, 0.15),\n",
    "        # ncol=3,\n",
    "        fancybox=True,\n",
    "        shadow=False,\n",
    "        fontsize=7,\n",
    "    )\n",
    "\n",
    "    # Adjust axis limits to prevent bars from touching the edges\n",
    "    ax1_min, ax1_max = ax1.get_ylim()\n",
    "    ax1.set_ylim(ax1_min * 1.15, ax1_max * 1.15)\n",
    "    ax2_min, ax2_max = ax2.get_ylim()\n",
    "    ax2.set_ylim(ax2_min * 1.15, ax2_max * 1.15)\n",
    "\n",
    "    # plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to make room for the title\n",
    "    plt.tight_layout()  # Adjust layout to make room for the title\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0985636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lmbd in diffs_pivot.lmbda.unique():\n",
    "    plot_ablation(diffs_pivot[diffs_pivot.lmbda == lmbd], lmbda_val=lmbd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d53fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same but in a table\n",
    "for lmbd in diffs_pivot.lmbda.unique():\n",
    "    print(f\"Lambda: {lmbd}\")\n",
    "    print(\n",
    "        diffs_pivot.loc[diffs_pivot.lmbda == lmbd][\n",
    "            [\"rate_nn_bpp_diff\", \"rate_latent_bpp_diff\", \"psnr_db_diff\"]\n",
    "        ].reset_index()\n",
    "    )\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb6f79e-cd22-42b0-9b01-56fe0782ccc3",
   "metadata": {},
   "source": [
    "# How many images use modulations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6c0e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_no_delta_perc(dataset):\n",
    "    results_path = RESULTS_DIR / \"exps/delta-hn/longer-ups-best-orange/\"\n",
    "    all_results = list(results_path.glob(f\"**/{dataset}_results.csv\"))\n",
    "\n",
    "    df = pd.concat(\n",
    "        [\n",
    "            pd.read_csv(res_file).assign(config=res_file.parents[1].name)\n",
    "            for res_file in all_results\n",
    "        ],\n",
    "        ignore_index=True,\n",
    "    )\n",
    "\n",
    "    # The ones that don't use a delta are shown as no_delta_noupsampling\n",
    "    no_deltas = df.option_selected == \"no_delta_noupsampling\"\n",
    "    return (\n",
    "        df[no_deltas]\n",
    "        .config.value_counts()\n",
    "        .reset_index()\n",
    "        .assign(percentage_ignored=lambda xdf: xdf[\"count\"] / len(df.seq_name.unique()))\n",
    "        .assign(perc_used=lambda df: 1 - df[\"percentage_ignored\"])\n",
    "        .assign(\n",
    "            lmbda=lambda df: df[\"config\"].apply(\n",
    "                lambda x: CONFIG_NUM_TO_LMBDA[x.split(\"_\")[-1]]\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "coolchic",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
