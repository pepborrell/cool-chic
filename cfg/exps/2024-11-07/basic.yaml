input: small.png
output: small.out
workdir: null
disable_wandb: False
load_models: False

enc_cfg:
  n_itr: 10000
  start_lr: 1e-2 # This should be removed, as it is hardcoded in every phase.
  n_train_loops: 1
  recipe:
    preset_name: c3x
    warmup:
      phases:
        - candidates: 5
          training_phase:
            lr: 1e-2
            max_itr: 400
            freq_valid: 400
            patience: 100000
            quantize_model: False
            schedule_lr: False
            softround_temperature: [0.3, 0.3]
            noise_parameter: [2.0, 2.0]
            quantizer_noise_type: "kumaraswamy"
            quantizer_type: "softround"
            optimized_module: ["all"]
        - candidates: 2
          training_phase:
            lr: 1e-2
            max_itr: 400
            freq_valid: 400
            patience: 100000
            quantize_model: False
            schedule_lr: False
            softround_temperature: [0.3, 0.3]
            noise_parameter: [2.0, 2.0]
            quantizer_noise_type: "kumaraswamy"
            quantizer_type: "softround"
            optimized_module: ["all"]
    all_phases:
      # 1st stage: with soft round and quantization noise
      - lr: 1e-2
        max_itr: 10600 # 10000 + 600
        patience: 5000
        optimized_module: ["all"]
        schedule_lr: True
        quantizer_type: softround
        quantizer_noise_type: gaussian
        softround_temperature: [0.3, 0.1]
        noise_parameter: [ 0.25, 0.1 ]
      # Stage with STE then network quantization
      - lr: 1e-4
        max_itr: 1500
        patience: 1500
        optimized_module: ["all"]
        schedule_lr: True
        quantizer_type: ste
        quantizer_noise_type: none
        # This is only used to parameterize the backward of the quantization
        softround_temperature: [ 1e-4, 1e-4 ]
        noise_parameter: [ 1.0, 1.0 ]  # not used since quantizer type is "ste"
        quantize_model: True  # ! This is an important parameter
      # Re-tune the latent
      - lr: 1.0e-4
        max_itr: 1000
        patience: 50
        quantizer_type: ste
        quantizer_noise_type: none
        optimized_module: ["latent"]  # ! Only fine tune the latent
        freq_valid: 10
        softround_temperature: [ 1e-4, 1e-4 ]
        noise_parameter: [ 1.0, 1.0 ]  # not used since quantizer type is "ste"

dec_cfg:
  arm: 8,2
  layers_synthesis: 16-1-linear-relu,3-1-linear-none,3-3-residual-relu,3-3-residual-none
  n_ft_per_res: 1,1,1,1,1,1,1
  upsampling_kernel_size: 4
  static_upsampling_kernel: False
