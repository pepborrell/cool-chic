n_samples: 500000
batch_size: 8
patch_size: [256, 256]
unfreeze_backbone: 10000
workdir: null
# model_weights: /itet-stor/jborrell/net_scratch/cool-chic/results/exps/no-cchic/orange-best/{lmbda_config_num}/model.pt
disable_wandb: False
lmbda: {lambda_value}
checkpoint: /itet-stor/jborrell/net_scratch/cool-chic/results/exps/delta-hn/ultimate-conference-run/{lmbda_config_num}/__latest
user_tag: delta-hn

recipe:
  preset_name: delta hnet training
  warmup:
    empty: True # This is a placeholder for the warmup phase.
  all_phases:
    - lr: 1e-4
      max_itr: 4000000
      quantize_model: False
      schedule_lr: True
      end_lr: 1e-6
      softround_temperature: [0.0, 0.0]
      noise_parameter: [1.0, 0.0]
      quantizer_noise_type: "kumaraswamy"
      quantizer_type: "true_ste"
      patience: 10000
      freq_valid: 5000
      checkpointing_freq: 50000
      gradient_accumulation: 1

hypernet_cfg:
  synthesis:
    hidden_dim: 1024
    n_layers: 3
    biases: False
    output_activation: null
  arm:
    hidden_dim: 1024
    n_layers: 3
    biases: False
    output_activation: null
  upsampling:
    hidden_dim: 256
    n_layers: 2
    output_activation: null
  backbone_arch: resnet50

  dec_cfg:
    config_name: hop
    arm: 16,2
    layers_synthesis: 48-1-linear-relu,X-1-linear-none,X-3-residual-relu,X-3-residual-none
    n_ft_per_res: 1,1,1,1,1,1,1
    ups_k_size: 8
    ups_preconcat_k_size: 7
    encoder_gain: 1
